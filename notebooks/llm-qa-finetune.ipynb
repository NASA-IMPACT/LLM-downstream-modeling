{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cf7a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9033e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fb44d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import transformers\n",
    "from transformers import (\n",
    "    RobertaConfig,\n",
    "    RobertaModel,\n",
    "    AutoTokenizer,\n",
    "    pipeline,\n",
    "    AutoModel,\n",
    "    RobertaTokenizerFast,\n",
    "    RobertaForQuestionAnswering\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5cd2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a169885",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990acf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a67fb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional, Dict, Union, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8740b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE THE MODEL\n",
    "\n",
    "configuration = RobertaConfig()\n",
    "configuration.vocab_size = 65536\n",
    "configuration.bos_token_id = 0\n",
    "configuration.device = \"cpu\"\n",
    "# configuration.pad_token_id = 1\n",
    "configuration.eos_token_id = 2\n",
    "configuration.pad_token_id = 0\n",
    "pprint(configuration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d728622",
   "metadata": {},
   "source": [
    "# Fine-Tuning for QA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791733cf",
   "metadata": {},
   "source": [
    "## Dataset prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d7228e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!pip install Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99193e46",
   "metadata": {},
   "source": [
    "### Load Custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cda6f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812f3724",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbc629f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4463db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c2a65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_askathon_clean(path: str) -> pd.DataFrame:\n",
    "    data = pd.read_csv(path)\n",
    "    data = data.drop(columns=[\"Email Address\"]).reset_index(drop=True)\n",
    "    data.rename(columns={\n",
    "        data.columns[0] : \"context\",\n",
    "        data.columns[1]: \"id\",\n",
    "        data.columns[2]: \"source\",\n",
    "        data.columns[3]: \"topics\",\n",
    "        data.columns[4]: \"q1\",\n",
    "        data.columns[5]: \"a1\",\n",
    "        data.columns[6]: \"q2\",\n",
    "        data.columns[7]: \"a2\",\n",
    "        data.columns[8]: \"q3\",\n",
    "        data.columns[9]: \"a3\",\n",
    "        data.columns[10]: \"q4\",\n",
    "        data.columns[11]: \"a4\",\n",
    "        data.columns[12]: \"q5\",\n",
    "        data.columns[13]: \"a5\"\n",
    "    }, inplace=True)\n",
    "    data.drop(columns=[\"source\", \"topics\"], inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8908e5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_qa_dataset(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    res = []\n",
    "    q_keys = [f\"q{i}\" for i in range(1, 6)]\n",
    "    a_keys = [f\"a{i}\" for i in range(1, 6)]\n",
    "    \n",
    "    def _index_fn(context: str, answer: str) -> int:\n",
    "        try:\n",
    "            return context.lower().index(answer.rstrip(\" ,.!?\").lower())\n",
    "        except ValueError:\n",
    "            return -1\n",
    "    \n",
    "    for _df in data.itertuples():\n",
    "        tmp = []\n",
    "        context = _df.context.strip()\n",
    "        for qk, ak in zip(q_keys, a_keys):\n",
    "            q, a = getattr(_df, qk), getattr(_df, ak)\n",
    "            \n",
    "            if not isinstance(a, str):\n",
    "                continue\n",
    "            idx = _index_fn(context, a)\n",
    "            if idx > -1:\n",
    "                tmp.append(dict(\n",
    "                    id=\"\".join(re.split(r\"[ :/]\", _df.id)),\n",
    "                    context=context,\n",
    "                    question=q,\n",
    "                    answer_text=a,\n",
    "                    answer_start=idx,\n",
    "                ))\n",
    "        res.extend(tmp)\n",
    "    return pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12248c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_qa = create_qa_dataset(load_askathon_clean(\"data/qa/Askathon Cleaned responses - Form Responses 1.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4519f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (max(data_qa[\"context\"], key=lambda x: len(x.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8adda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# will be easier for downstream preprocessing\n",
    "data_qa[\"answers\"] = data_qa[[\"answer_text\", \"answer_start\"]]\\\n",
    ".apply(lambda r: dict(text=[r[0]], answer_start=[r[1]]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bdd143",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_qa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f646ef4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_qa_train, data_qa_test = train_test_split(data_qa, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc17807",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_qa_train.shape, data_qa_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf01a4c",
   "metadata": {},
   "source": [
    "### Preprocess for training\n",
    "\n",
    "- tokenization\n",
    "- chunking\n",
    "- etc\n",
    "\n",
    "References:\n",
    "- https://huggingface.co/docs/transformers/tasks/question_answering\n",
    "- https://github.com/AmitNikhade/Kaggle/blob/main/chaii%20-%20Hindi%20and%20Tamil%20Question%20Answering/question-answering-roberta-starter-explained.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7000c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"data/nasawiki-v6/\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"data/sq2-v6/train-watbertv6-squad-2ep/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3251f495",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.max_len_single_sentence, tokenizer.padding_side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d082b856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.padding_side == \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0a5d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function_1(examples, tokenizer, max_length=382, stride=128):\n",
    "    # Some of the questions have lots of whitespace on the left, which is not useful and will make the\n",
    "    # truncation of the context fail (the tokenized question will take a lots of space). So we remove that\n",
    "    # left whitespace\n",
    "#     examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n",
    "    \n",
    "    pad_on_right = tokenizer.padding_side == \"right\"\n",
    "\n",
    "    # Tokenize our examples with truncation and padding, but keep the overflows using a stride. This results\n",
    "    # in one example possible giving several features when a context is long, each of those features having a\n",
    "    # context that overlaps a bit the context of the previous feature.\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[\"question\" if pad_on_right else \"context\"],\n",
    "        examples[\"context\" if pad_on_right else \"question\"],\n",
    "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
    "        max_length=max_length,\n",
    "        stride=stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    # Since one example might give us several features if it has a long context, we need a map from a feature to\n",
    "    # its corresponding example. This key gives us just that.\n",
    "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "    # The offset mappings will give us a map from token to character position in the original context. This will\n",
    "    # help us compute the start_positions and end_positions.\n",
    "    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
    "\n",
    "    # Let's label those examples!\n",
    "    tokenized_examples[\"start_positions\"] = []\n",
    "    tokenized_examples[\"end_positions\"] = []\n",
    "\n",
    "    for i, offsets in enumerate(offset_mapping):\n",
    "        # We will label impossible answers with the index of the CLS token.\n",
    "        input_ids = tokenized_examples[\"input_ids\"][i]\n",
    "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
    "\n",
    "        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n",
    "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "\n",
    "        # One example can give several spans, this is the index of the example containing this span of text.\n",
    "        sample_index = sample_mapping[i]\n",
    "        answers = examples[\"answers\"][sample_index]\n",
    "        # If no answers are given, set the cls_index as answer.\n",
    "        if len(answers[\"answer_start\"]) == 0:\n",
    "            tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "            tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "        else:\n",
    "            # Start/end character index of the answer in the text.\n",
    "            start_char = answers[\"answer_start\"][0]\n",
    "            end_char = start_char + len(answers[\"text\"][0])\n",
    "\n",
    "            # Start token index of the current span in the text.\n",
    "            token_start_index = 0\n",
    "            while sequence_ids[token_start_index] != (1 if pad_on_right else 0):\n",
    "                token_start_index += 1\n",
    "\n",
    "            # End token index of the current span in the text.\n",
    "            token_end_index = len(input_ids) - 1\n",
    "            while sequence_ids[token_end_index] != (1 if pad_on_right else 0):\n",
    "                token_end_index -= 1\n",
    "\n",
    "            # Detect if the answer is out of the span (in which case this feature is labeled with the CLS index).\n",
    "            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
    "                tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "                tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "            else:\n",
    "                # Otherwise move the token_start_index and token_end_index to the two ends of the answer.\n",
    "                # Note: we could go after the last offset if the answer is the last word (edge case).\n",
    "                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
    "                    token_start_index += 1\n",
    "                tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n",
    "                while offsets[token_end_index][1] >= end_char:\n",
    "                    token_end_index -= 1\n",
    "                tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n",
    "\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246b5c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function_2(examples, tokenizer, max_length=384, stride=128):\n",
    "#     questions = list(map(lambda x: x[\"question\"], examples))\n",
    "    inputs = tokenizer(\n",
    "        examples[\"question\"],\n",
    "        examples[\"context\"],\n",
    "        max_length=max_length,\n",
    "        truncation=\"only_second\",\n",
    "        stride=stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    sample_mapping = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    answers = examples[\"answers\"]\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        \n",
    "        input_ids = inputs[\"input_ids\"][i]\n",
    "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
    "        \n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "        \n",
    "        sample_index = sample_mapping[i]\n",
    "\n",
    "        answer = answers[sample_index]\n",
    "        start_char = answer[\"answer_start\"][0]\n",
    "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
    "\n",
    "\n",
    "        # Find the start and end of the context\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "\n",
    "        # If the answer is not fully inside the context, label it (0, 0)\n",
    "        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            # Otherwise it's the start and end token positions\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1)\n",
    "\n",
    "            idx = context_end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1)\n",
    "\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b0abfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess_function(data_qa_train.iloc[:2, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d524c323",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(data_qa_train)\n",
    "test_dataset = Dataset.from_pandas(data_qa_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1981b24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261fb2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_trains = train_dataset.map(\n",
    "    functools.partial(preprocess_function_2, tokenizer=tokenizer, max_length=384, stride=128),\n",
    "    batched=True,\n",
    "    remove_columns=train_dataset.column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986de173",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_tests = test_dataset.map(\n",
    "    functools.partial(preprocess_function_2, tokenizer=tokenizer, max_length=384, stride=128),\n",
    "    batched=True,\n",
    "    remove_columns=test_dataset.column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e2e727",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_trains, tokenized_tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a7806b",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a743fd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e8cc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer, default_data_collator\n",
    "from transformers import AutoModelForQuestionAnswering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019f6315",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63d87a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = AutoModelForQuestionAnswering.from_pretrained(\"data/sq2-v6/train-watbertv6-squad-2ep/\")\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"data/nasawiki-v6/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9beeb123",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1111a9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathlib.Path(model.name_or_path).stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1407f6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a27b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    project=\"llm-test\",\n",
    "    entity=\"nish-test\",\n",
    "    tags=[\"qa\", pathlib.Path(model.name_or_path).stem]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ec76a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_args = TrainingArguments(\n",
    "    f\"tmp/finetuned/qa/{pathlib.Path(model.name_or_path).stem}\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    learning_rate=3e-5,\n",
    "    warmup_ratio=0.1,\n",
    "    gradient_accumulation_steps=8,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    report_to=\"wandb\",\n",
    "    logging_steps=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44671f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_args.output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2abdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    train_args,\n",
    "    train_dataset=tokenized_trains,\n",
    "    eval_dataset=tokenized_tests,\n",
    "    data_collator=default_data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9ec1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d1bf1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85e39078",
   "metadata": {},
   "source": [
    "## predict/evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e2dcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "from rapidfuzz import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfad641",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jury import Jury"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f376181",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_pipe = pipeline(\n",
    "    \"question-answering\",\n",
    "    model=\"tmp/finetuned/qa/nasawiki-v6/checkpoint-30/\",\n",
    "    tokenizer=\"tmp/finetuned/qa/nasawiki-v6/checkpoint-30/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2129dd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_pipe.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ef28c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = qa_pipe(\n",
    "    list(map(lambda x: dict(context=x[\"context\"], question=x[\"question\"]), data_qa_train.to_dict(\"records\")))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264dfc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335faa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c00628c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_fuzzy(gts: List[str], predictions: List[str]):\n",
    "    _preprocess = lambda x: x.strip(\" .,!?\").lower()\n",
    "    gts = list(map(_preprocess, gts))\n",
    "    predictions = list(map(_preprocess, predictions))\n",
    "    res = []\n",
    "    for gt, pred in zip(gts, predictions):\n",
    "        res.append(fuzz.token_set_ratio(gt, pred))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6ff935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_exact(gts: List[str], predictions: List[str]):\n",
    "    _preprocess = lambda x: x.strip(\" .,!?\").lower()\n",
    "    gts = list(map(_preprocess, gts))\n",
    "    predictions = list(map(_preprocess, predictions))\n",
    "    res = []\n",
    "    for gt, pred in zip(gts, predictions):\n",
    "        res.append((gt == pred)*100)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d2756c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_squad_1(gts: List[dict], predictions: List[str], squad_metric):\n",
    "    predictions = list(map(lambda x: dict(prediction_text=x[1], id=str(x[0])), enumerate(predictions)))\n",
    "\n",
    "    references = list(map(\n",
    "        lambda x: {\"answers\": dict(\n",
    "            answer_start=[x[0][\"answer_start\"]],\n",
    "            text=[x[0][\"answer_text\"]],\n",
    "        ), \"id\": x[1][\"id\"]},\n",
    "        zip(gts, predictions)\n",
    "    ))\n",
    "    \n",
    "    print(references[0])\n",
    "    print(predictions[0])\n",
    "    \n",
    "    return squad_metric.compute(\n",
    "        predictions=predictions,\n",
    "        references=references,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460a246d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_squad_2(gts: List[dict], predictions: List[dict], squad_metric):\n",
    "\n",
    "    references = list(map(\n",
    "        lambda x: {\"answers\": dict(\n",
    "            answer_start=[x[\"answer_start\"]],\n",
    "            text=[x[\"answer_text\"]],\n",
    "        ), \"id\": x[\"id\"]},\n",
    "        gts\n",
    "    ))\n",
    "    \n",
    "    print(references[0])\n",
    "    print(predictions[0])\n",
    "    return squad_metric.compute(\n",
    "        predictions=predictions,\n",
    "        references=references,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ab2353",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = evaluate_exact(\n",
    "    data_qa_train[\"answer_text\"].to_list(),\n",
    "    list(map(lambda p: p[\"answer\"], predictions)),\n",
    ")\n",
    "print(np.mean(res))\n",
    "sns.boxplot(res)\n",
    "plt.title(\"Ground truth vs prediction exact match\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4d10c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = evaluate_fuzzy(\n",
    "    data_qa_train[\"answer_text\"].to_list(),\n",
    "    list(map(lambda p: p[\"answer\"], predictions)),\n",
    ")\n",
    "print(np.mean(res))\n",
    "sns.boxplot(res)\n",
    "plt.title(\"Ground truth vs prediction fuzzy match\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035b0561",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_squad_1(\n",
    "    gts=data_qa_test.to_dict(\"records\"),\n",
    "    predictions=list(map(lambda p: p[\"answer\"], predictions)),\n",
    "    squad_metric=evaluate.load(\"squad\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c93caba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluate_squad_2(\n",
    "    gts=data_qa_test.to_dict(\"records\"),\n",
    "    predictions=list(map(lambda p: dict(prediction_text=p[0][\"answer\"], id=p[1]), zip(predictions, data_qa_test[\"id\"]))),\n",
    "    squad_metric=evaluate.load(\"squad\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9826cf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_squad_3(\n",
    "#     gts=data_qa_test.to_dict(\"records\"),\n",
    "#     predictions=list(map(lambda p: p[\"answer\"], predictions)),\n",
    "#     squad_metric=evaluate.load(\"squad\"),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adc3544",
   "metadata": {},
   "outputs": [],
   "source": [
    "_peek_predictions(\n",
    "    gts=data_qa_test.to_dict(\"records\"),\n",
    "    predictions=list(map(lambda p: dict(prediction_text=p[0][\"answer\"], id=p[1]), zip(predictions, data_qa_test[\"id\"]))),\n",
    "    index=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d807b0fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635377bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jury"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf6471a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_preprocess_fn = lambda x: x.strip(\" .,!?\").lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e836c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Jury(metrics=[\"exact_match\", \"bleu\", \"squad\"])(\n",
    "    predictions=list(map(lambda p: p[\"answer\"], predictions)),\n",
    "    references=data_qa_train[\"answer_text\"].to_list(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bf4877",
   "metadata": {},
   "outputs": [],
   "source": [
    "Jury(metrics=[\"exact_match\", \"bleu\", \"squad\"])(\n",
    "    predictions=list(map(lambda p: _preprocess_fn(p[\"answer\"]), predictions)),\n",
    "    references=list(map(_preprocess_fn, data_qa_train[\"answer_text\"].to_list())),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a25615c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Jury(metrics=[\"squad\"])(\n",
    "    predictions=list(map(lambda p: p[\"answer\"], predictions)),\n",
    "    references=data_qa_test[\"answer_text\"].to_list(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaad87c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
