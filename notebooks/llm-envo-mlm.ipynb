{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cf7a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9033e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fb44d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import transformers\n",
    "from transformers import (\n",
    "    RobertaConfig,\n",
    "    RobertaModel,\n",
    "    AutoTokenizer,\n",
    "    pipeline,\n",
    "    AutoModel,\n",
    "    RobertaTokenizerFast\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5cd2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990acf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbce1b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8740b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE THE MODEL\n",
    "\n",
    "configuration = RobertaConfig()\n",
    "configuration.vocab_size = 65536\n",
    "configuration.bos_token_id = 0\n",
    "configuration.device = \"cpu\"\n",
    "# configuration.pad_token_id = 1\n",
    "configuration.eos_token_id = 2\n",
    "configuration.pad_token_id = 0\n",
    "pprint(configuration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4506a6b3",
   "metadata": {},
   "source": [
    "# Fine Tune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9103ead6",
   "metadata": {},
   "source": [
    "## load meronyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341e53cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb734de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = \"ice is a form of <mask>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c28eeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "# token_logits = model_ft(**inputs).logits\n",
    "\n",
    "# # Find the location of [MASK] and extract its logits\n",
    "# mask_token_index = torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)[1]\n",
    "# mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "\n",
    "# # Pick the [MASK] candidates with the highest logits\n",
    "# k = 10\n",
    "# top_k_tokens = torch.topk(mask_token_logits, k, dim=1).indices[0].tolist()\n",
    "\n",
    "# for token in top_k_tokens:\n",
    "#     print(f\"'>>> {text.replace(tokenizer.mask_token, tokenizer.decode([token]))}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa61ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_meronyms_bc(path):\n",
    "    # 1st column-pair (B, C), skip 1st 4 text data\n",
    "    meronyms = pd.read_csv(path)\n",
    "    meronyms = meronyms.iloc[8:, 1:3].copy().reset_index(drop=True)\n",
    "    meronyms.columns = [\"part\", \"whole\"]\n",
    "    return meronyms.dropna().reset_index(drop=True)\n",
    "\n",
    "def load_meronyms_de(path):\n",
    "    # for 2nd-column pair: (D, E)\n",
    "    meronyms = pd.read_csv(path)\n",
    "    meronyms = meronyms.iloc[4:, 3:5].copy().reset_index(drop=True)\n",
    "    meronyms.columns = [\"whole\", \"part\"]\n",
    "    return meronyms.dropna().reset_index(drop=True)\n",
    "\n",
    "\n",
    "def load_meronyms_fg(path):\n",
    "    # for 3rd-column pair: (F, G)\n",
    "    meronyms = pd.read_csv(path)\n",
    "    meronyms = meronyms.iloc[4:, 5:7].copy().reset_index(drop=True)\n",
    "    meronyms.columns = [\"whole\", \"part\"]\n",
    "    return meronyms.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3ca81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "meronyms = load_meronyms_bc(\"data/ENVO Tags - Relationships_Lexico.csv\")\n",
    "# meronyms = load_meronyms_de(\"data/ENVO Tags - Relationships_Lexico.csv\")\n",
    "# meronyms = load_meronyms_fg(\"data/ENVO Tags - Relationships_Lexico.csv\")\n",
    "meronyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2734c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "meronyms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbe586d",
   "metadata": {},
   "outputs": [],
   "source": [
    "meronyms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23c5f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# meronyms[\"part\"] = meronyms.apply(lambda r: \"_\".join(r.part), axis=1)\n",
    "# meronyms[\"whole\"] = meronyms.apply(lambda r: \"_\".join(r.whole), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6fe9b3",
   "metadata": {},
   "source": [
    "## preprocess texts for MLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085e2719",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd48d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_pairs(part:str, whole: str) -> List[str]:\n",
    "    return [\n",
    "        f\" {part} is a part of {whole}.\",\n",
    "        f\" {part} is a component of {whole}.\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615852bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_pairs(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    data = data.copy()\n",
    "    data[\"augmented\"] = data.apply(\n",
    "        lambda r: [\n",
    "            f\" {r.part} is a part of {r.whole}.\",\n",
    "            f\" {r.part} is a component of {r.whole}.\",\n",
    "    #         f\" {r.whole} is composed of {r.part}.\",\n",
    "    #         f\" {r.whole} consists of {r.part}.\",\n",
    "        ], \n",
    "        axis=1\n",
    "    )\n",
    "    return data.explode(\"augmented\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6e7a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "meronyms = augment_pairs(meronyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a4cafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "meronyms.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20a7bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "meronyms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa18707",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/meronyms-augmented.txt\", \"w\") as f:\n",
    "    f.writelines(\"\\n\".join(meronyms[\"augmented\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c1f8e2",
   "metadata": {},
   "source": [
    "## create dataloader for MLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99404530",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LineByLineTextDataset\n",
    "from transformers import DataCollatorForLanguageModeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d155e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93987122",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437089aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(\"./nasa-wiki-weighted-tokenizer-10-3-22/\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "# tokenizer = RobertaTokenizerFast.from_pretrained(\"roberta-base\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"data/sq2-v6/train-watbertv6-squad-2ep/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57604b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af5f66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LineByLineTextDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path=\"data/meronyms-augmented.txt\",\n",
    "    block_size=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1056f798",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e940b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @dataclass\n",
    "# class CustomDataCollatorForLanguageModeling(DataCollatorForLanguageModeling):\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31841e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=True, mlm_probability=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d140f687",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0190495f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05773fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edb5728",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f501a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297054ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForMaskedLM.from_pretrained(\"data/sq2-v6/train-watbertv6-squad-2ep/\")\n",
    "# model = AutoModelForMaskedLM.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b5fa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b4a647",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8535428",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    project=\"llm-test\",\n",
    "    entity=\"nish-test\",\n",
    "    tags=[\n",
    "        \"envo-mlm\", \n",
    "        pathlib.Path(model.name_or_path).stem,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f25243a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    f\"tmp/finetuned/envo-mlm/{pathlib.Path(model.name_or_path).stem}\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=128,\n",
    "    learning_rate=3e-5,\n",
    "    save_steps=10_000,\n",
    "    save_total_limit=2,\n",
    "    prediction_loss_only=True,\n",
    "    report_to=\"wandb\",\n",
    "      weight_decay=0.01,\n",
    "#     evaluation_strategy='steps',\n",
    "    logging_steps=1,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718b6fc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747ba13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"tmp/finetuned/envo-mlm/test/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1315f34c",
   "metadata": {},
   "source": [
    "# Accuracy check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008e01a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496a9673",
   "metadata": {},
   "outputs": [],
   "source": [
    "unmasker = pipeline(\n",
    "    \"fill-mask\",\n",
    "    model=\"tmp/finetuned/envo-mlm/test/\",\n",
    "    tokenizer=\"data/sq2-v6/train-watbertv6-squad-2ep/\"\n",
    "#     tokenizer=tokenizer\n",
    "#     tokenizer=\"roberta-base\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c767f14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_meronyms_de(\"data/ENVO Tags - Relationships_Lexico.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b561408",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb7c8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask the whole\n",
    "data = data[(data.whole.str.split().str.len())==1].reset_index(drop=True)\n",
    "data[\"test\"] = data.apply(lambda r: f\" {r.part} is a part of <mask>.\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dccc49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask the part\n",
    "# data = data[(data.part.str.split().str.len())==1].reset_index(drop=True)\n",
    "# data[\"test\"] = data.apply(lambda r: f\" <mask> is a part of {r.whole}.\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d2b17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f1200a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed63dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6837cc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = unmasker(data.test.to_list(), top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dad90c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe9db30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(predictions: List[List[dict]], gts: List[str]):\n",
    "    matched = 0\n",
    "    for (gt, preds) in zip(gts, predictions):\n",
    "        gt = gt.strip()\n",
    "        preds = list(map(lambda p: p[\"token_str\"].strip(), preds))\n",
    "        if gt in preds:\n",
    "            matched += 1\n",
    "    return matched/len(gts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701a1ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if \"whole\" was masked\n",
    "analyze(predictions, data.whole.to_list()) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e0fa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if \"part\" was masked\n",
    "analyze(predictions, data.part.to_list()) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af5d941",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
